{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Project\n",
    "## Convolutional Neural Network for image recognition of chest X-rays to help fighting Covid-19 pandemy. <br>\n",
    "\n",
    "Author: Piotr Druzdzel <br>\n",
    "E-mail: piotr.druzdzel@gmail.com <br><br>\n",
    "\n",
    "Data source: Kaggle <br>\n",
    "https://www.kaggle.com/praveengovi/coronahack-chest-xraydataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coronaviruses are a group of related RNA viruses that cause diseases in mammals and birds. In humans, these viruses cause respiratory tract infections that can range from mild to lethal. Coronaviruses can cause pneumonia (either direct viral pneumonia or secondary bacterial pneumonia) and bronchitis (either direct viral bronchitis or secondary bacterial bronchitis). <br>\n",
    "\n",
    "Chest X-ray images are one of the important imaging methods that help to discover the presence of the disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COVID-19 affects different people in different ways. Most infected people will develop mild to moderate illness and recover without hospitalization.\n",
    "\n",
    "#### Most common symptoms:\n",
    "fever, dry cough, tiredness\n",
    "\n",
    "#### Less common symptoms:\n",
    "aches and pains, sore throat, diarrhoea, conjunctivitis, headache, loss of taste or smell, a rash on skin, or discolouration of fingers or toes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timing the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dark theme fix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the metadata with an overview of available images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\\\Chest_xray_Corona_Metadata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop 'Unnamed 0' column:\n",
    "(It does not add any value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring 'Label' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['Label']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['Dataset_type'], hue=df['Label']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label 1 Virus Category:\n",
    "No information if the 'Virus' samples pertain to COVID-19:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,4))\n",
    "sns.countplot(df['Dataset_type'], hue=df['Label_1_Virus_category']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label 2 Virus Category:\n",
    "No COVID-19 data in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,4))\n",
    "sns.countplot(df['Dataset_type'], hue=df['Label_2_Virus_category']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No COVID-19 in the Test directory:\n",
    "Only NaN in the 'Label_2_Virus_category' for the Test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Dataset_type']=='TEST')]['Label_2_Virus_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Dataset_type']=='TEST')]['Label_1_Virus_category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring 'Label 1 Virus Category':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "viridis = cm.get_cmap('viridis', 28) #import colormap\n",
    "\n",
    "virus    = df[df['Label_1_Virus_category']=='Virus']['Label'].count()            #int\n",
    "bacteria = df[df['Label_1_Virus_category']=='bacteria']['Label'].count()         #int\n",
    "stress   = df[df['Label_1_Virus_category']=='Stress-Smoking']['Label'].count()   #int\n",
    "\n",
    "dark = cm.get_cmap('Dark2') #import colormap\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize=(22, 6))\n",
    "\n",
    "axes[0]=plt.subplot(1,2,1)\n",
    "sns.barplot(y = [virus, bacteria, stress],\n",
    "            x = ['Virus','Bacteria', 'Stress-Smoking'], \n",
    "            palette=dark(np.linspace(0, 2, 8)))\n",
    "plt.title('Number of specific reasons')\n",
    "\n",
    "axes[1]=plt.subplot(1,2,2)\n",
    "plt.pie([virus, bacteria, stress],\n",
    "        labels = ['Virus','Bacteria', 'Stress-Smoking'],\n",
    "        autopct = '%1.2f%%',\n",
    "        textprops={'fontsize': 16, 'color':'silver'},\n",
    "        startangle = 120,\n",
    "        explode = [0.1,0,0],\n",
    "        colors = dark(np.linspace(0, 2, 8)))\n",
    "plt.title(\"Percentage of specific reasons\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring 'Label 2 Virus Category':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streptococcus = df[df['Label_2_Virus_category']=='Streptococcus']['Label'].count()    #int\n",
    "covid19       = df[df['Label_2_Virus_category']=='COVID-19']['Label'].count()         #int\n",
    "ards          = df[df['Label_2_Virus_category']=='ARDS']['Label'].count()             #int\n",
    "sars          = df[df['Label_2_Virus_category']=='SARS']['Label'].count()             #int\n",
    "\n",
    "dark = cm.get_cmap('Dark2') #import colormap\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2,figsize=(22, 6))\n",
    "\n",
    "axes[0]=plt.subplot(1,2,1)\n",
    "sns.barplot(y = [streptococcus, covid19, ards, sars],\n",
    "            x = ['Streptococcus','COVID-19', 'ARDS','SARS'], \n",
    "            palette=dark(np.linspace(0, 2, 8)))\n",
    "plt.title('Number of specific reasons')\n",
    "\n",
    "axes[1]=plt.subplot(1,2,2)\n",
    "plt.pie([streptococcus, covid19, ards, sars],\n",
    "        labels = ['Streptococcus','COVID-19', 'ARDS','SARS'],\n",
    "        autopct = '%1.0f%%',\n",
    "        textprops={'fontsize': 16, 'color':'silver'},\n",
    "        startangle = 180,\n",
    "        explode = [0.2, 0.1, 0.2, 0],\n",
    "        colors = dark(np.linspace(0, 2, 8)))\n",
    "plt.title(\"Percentage of specific reasons\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create 'Path' column\n",
    "Assign training and test paths with all samples respectively (label-based indexing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Dataset_type']=='TRAIN', 'Path'] = '.\\\\dataset\\\\train\\\\all\\\\'\n",
    "df.loc[df['Dataset_type']=='TEST', 'Path'] = '.\\\\dataset\\\\test\\\\all\\\\'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add column with path+unique image name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Image_path'] = df['Path'] + df['X_ray_image_name']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting labelled training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[(df['Dataset_type']=='TRAIN') & ((df['Label']=='Normal')|(df['Label_2_Virus_category']=='COVID-19'))]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_train['Label'], order=['Normal', 'Pnemonia']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting labelled test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test = df[(df['Dataset_type']=='TEST') & ((df['Label']=='Normal')|(df['Label_2_Virus_category']=='COVID-19'))]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data count - problem: only 'heatlhy' samples :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_test['Label'], order=['Normal', 'Pnemonia']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The percentage of infected samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df_train.loc[:,'Label'].count()\n",
    "infected = df_train.loc[df_train['Label']=='Pnemonia']['Label'].count()\n",
    "\n",
    "print(f'In the training set, infected samples take up: {np.round(infected/normal*100, 2)} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 infected samples in the test set will maintain similar proportion w.r.t training set.\n",
    "To prevent model from always predicting 'Normal' class and still having high accuracy, let's add more COVID-19 cases to the test set to evaluate its response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = np.round(10/df_test.loc[df_test['Label']=='Normal']['Label'].count()*100, 2)\n",
    "print(f'In the test set, infected samples take up: {percentage}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving random Corona-infected samples from Training to Test set:\n",
    "Select the additional samples from training set and add to the test set.\n",
    "Then, remove the selected samples from training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df[df['Label_2_Virus_category']=='COVID-19'].sample(10)\n",
    "df_test = pd.concat([samples, df_test], ignore_index=False)\n",
    "\n",
    "df_train = df_train[~df_train['X_ray_image_name'].isin(samples['X_ray_image_name'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-check the distribution of samples for the Test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_test['Label'], order=['Normal', 'Pnemonia']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename 'Pnemonia' to 'COVID-19' labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['Label'] =='Pnemonia', 'Label'] = 'COVID19'\n",
    "df_test.loc[df_test['Label'] =='Pnemonia', 'Label'] = 'COVID19'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The distribution of pre-processed training and test data::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14,4))\n",
    "\n",
    "sns.countplot(df_train['Label'], \n",
    "              order=['Normal', 'COVID19'],\n",
    "              ax=ax[0])\n",
    "\n",
    "sns.countplot(df_test['Label'], \n",
    "              order=['Normal', 'COVID19'],\n",
    "              ax=ax[1]);\n",
    "\n",
    "ax[0].title.set_text('Pre-processed Training set')\n",
    "ax[1].title.set_text('Pre-processed Test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exact number of samples in trainig and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set:')\n",
    "print(df_train.groupby(['Label']).agg({'Dataset_type':'count'}))\n",
    "\n",
    "print('\\nTest Set:')\n",
    "print(df_test.groupby(['Label']).agg({'Dataset_type':'count'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating folder structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_normal = '.\\\\dataset\\\\train\\\\classes\\\\normal\\\\'\n",
    "train_path_covid = '.\\\\dataset\\\\train\\\\classes\\\\covid\\\\'\n",
    "\n",
    "test_path_normal = '.\\\\dataset\\\\test\\\\classes\\\\normal\\\\'\n",
    "test_path_covid = '.\\\\dataset\\\\test\\\\classes\\\\covid\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create target paths in the metadata overview DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['Label'] == 'Normal','Target_path'] = train_path_normal\n",
    "df_train.loc[df_train['Label'] == 'COVID19','Target_path'] = train_path_covid\n",
    "\n",
    "df_test.loc[df_test['Label'] == 'Normal','Target_path'] = test_path_normal\n",
    "df_test.loc[df_test['Label'] == 'COVID19','Target_path'] = test_path_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "paths = [train_path_normal, train_path_covid, test_path_normal, test_path_covid]\n",
    "\n",
    "for path in paths:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f'Path not present before. Created new: {path}')\n",
    "    else:\n",
    "        shutil.rmtree(path) #removes all the subdirectories!\n",
    "        os.makedirs(path)\n",
    "        print(f'Path present. Removed the previous content and created new: {path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolated source and target paths for copying training images to their separate folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['Image_path', 'Target_path']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolated source and target paths for copying test images to their separate folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['Image_path', 'Target_path']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy files from /all folder to /train and /covid folders:\n",
    "Two for loops: training and test dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source, destination in df_train[['Image_path', 'Target_path']].itertuples(index=False):\n",
    "    try:\n",
    "        shutil.copy(source, destination)\n",
    "        df_train[\"Copying\"] = 'Successful'\n",
    "    except:\n",
    "        print('Failed')\n",
    "        \n",
    "for source, destination in df_test[['Image_path', 'Target_path']].itertuples(index=False):\n",
    "    try:\n",
    "        shutil.copy(source, destination)\n",
    "        df_test[\"Copying\"] = 'Successful'\n",
    "    except:\n",
    "        print('Failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assert that all rows were copied successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Copy operations messages for training data: {df_train['Copying'].unique()}\")\n",
    "print(f\"Copy operations messages for test data: {df_test['Copying'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample images for visualization purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_normal_image = train_path_normal + os.listdir(train_path_normal)[1]\n",
    "sample_train_covid_image = train_path_covid + os.listdir(train_path_covid)[1]\n",
    "\n",
    "sample_test_normal_image = test_path_normal + os.listdir(test_path_normal)[1]\n",
    "sample_test_covid_image = test_path_covid + os.listdir(test_path_covid)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the sample train and test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "img_train_normal = mpimg.imread(sample_train_normal_image)    #Training normal\n",
    "img_train_covid = mpimg.imread(sample_train_covid_image)      #Training covid\n",
    "\n",
    "img_test_normal = mpimg.imread(sample_test_normal_image)      #Test normal\n",
    "img_test_covid = mpimg.imread(sample_test_covid_image)        #Test covid\n",
    "\n",
    "fig, ax = plt.subplots(4,2, figsize=(22, 22))\n",
    "\n",
    "#Training normal\n",
    "ax[0, 0].imshow(img_train_normal, cmap='gray');\n",
    "ax[0, 0].title.set_text('Training - Normal')\n",
    "\n",
    "ax[0, 1].hist(img_train_normal.ravel(), bins=256, fc='silver', ec='w');\n",
    "ax[0, 1].title.set_text('Training - Normal')\n",
    "\n",
    "#Training covid\n",
    "ax[1, 0].imshow(img_train_covid, cmap='gray');\n",
    "ax[1, 0].title.set_text('Training - Covid-19')\n",
    "\n",
    "ax[1, 1].hist(img_train_covid.ravel(), bins=256, fc='silver', ec='w');\n",
    "ax[1, 1].title.set_text('Training - Covid-19')\n",
    "\n",
    "#Test normal\n",
    "ax[2, 0].imshow(img_test_normal, cmap='gray');\n",
    "ax[2, 0].title.set_text('Test - Normal')\n",
    "\n",
    "ax[2, 1].hist(img_test_normal.ravel(), bins=256, fc='silver', ec='w');\n",
    "ax[2, 1].title.set_text('Test - Normal')\n",
    "\n",
    "#Test covid\n",
    "ax[3, 0].imshow(img_test_covid, cmap='gray');\n",
    "ax[3, 0].title.set_text('Test - Covid-19')\n",
    "\n",
    "ax[3, 1].hist(img_test_covid.ravel(), bins=256, fc='silver', ec='w');\n",
    "ax[3, 1].title.set_text('Test - Covid-19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image augmentation with Keras ImageDataGenerator class:\n",
    "Image data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset. Image data augmentation is typically only applied to the training dataset, and not to the validation or test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    \n",
    "    rescale = 1./255,              #each pixel 0-1\n",
    "    brightness_range = [0.7,1.3],  #brightness +/- 30%\n",
    "    rotation_range = 20,           #rotate\n",
    "    width_shift_range = 0.1,       #shift the image in the horizontal direction by 10% of its width\n",
    "    height_shift_range = 0.1,      #shift the image in the vertical direction by 10% of its width\n",
    "    shear_range = 0.2,             #shear angle in the counter-clockwise direction in degrees\n",
    "    horizontal_flip = True,        #randomly flips the input image in the horizontal direction\n",
    "    fill_mode = 'nearest')         #points that exceed the boundary will be processed according to their closest pixels\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate batches of tensor image data through real-time data augmentation:\n",
    "The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the model’s internal parameters are updated. <br>\n",
    "\n",
    "The number of epochs is a hyperparameter of gradient descent that controls the number of complete passes through the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Traning set: \")\n",
    "train_iterator = train_datagen.flow_from_directory('.\\\\dataset\\\\train\\\\classes\\\\', #each class should have its subdirectory\n",
    "                                                   target_size=(150, 150), \n",
    "                                                   batch_size = 32,\n",
    "                                                   class_mode = 'binary')\n",
    "\n",
    "print(\"Test set: \")\n",
    "test_iterator = test_datagen.flow_from_directory('.\\\\dataset\\\\test\\\\classes\\\\',\n",
    "                                                 target_size=(150, 150),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The results of image augmentation:\n",
    "10 first examples from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_iterator.next()\n",
    "\n",
    "fig, ax = plt.subplots(2,10, figsize=(22, 4))\n",
    "ax = ax.ravel() #otherwise axs is a multidim. array that cannot be iterated over\n",
    "\n",
    "for i in range(20):\n",
    "    ax[i].imshow(x[i,:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Convolutional Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "#Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 32,                #number of output filters in the convolution\n",
    "                               kernel_size = 3,             #convolution window - feature detector size\n",
    "                               activation = 'relu',         #rectified linear unit to increase the non-linearity of \n",
    "                               input_shape = (150,150,3)))  #input tensor: 150 x 150 pixels x 3 channels\n",
    "#Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,              #pooling window size - as usual: 2x2\n",
    "                                  strides=2))               #how far the pooling window moves for each pooling step\n",
    "#Second convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 64,\n",
    "                               kernel_size = 3,\n",
    "                               activation = 'relu',\n",
    "                               input_shape = (150,150,3)))\n",
    "#Second pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,\n",
    "                                  strides=2))\n",
    "#Third convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 128,\n",
    "                               kernel_size = 3,\n",
    "                               activation = 'relu',\n",
    "                               input_shape = (150,150,3)))\n",
    "#Third pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,\n",
    "                                  strides=2))\n",
    "#Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "      \n",
    "#Full connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128,\n",
    "                              activation='relu'))\n",
    "#Dropout layer\n",
    "cnn.add(tf.keras.layers.Dropout(rate=0.5)) #switch off 50% of the neurons for each batch of training to prevent overfitting\n",
    "        \n",
    "#Output layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1,\n",
    "                              activation='sigmoid'))\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer ='adam',            #Adaptive Moment Estimation - includes momentum\n",
    "            loss='binary_crossentropy',   #two classes: Normal and COVID19\n",
    "            metrics = ['accuracy'])             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks: Earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           mode='min',             #minimazing the validation loss, 'auto' usually works fine too\n",
    "                           verbose=2,              #print feedback with the progress\n",
    "                           patience=25)            #number of epochs to still do after detecting the stopping point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Yellow\">Training the model:</span>\n",
    "(25 epochs take ~38 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(train_iterator,\n",
    "        steps_per_epoch = train_iterator.samples//32, #floor division: samples/batch size\n",
    "        epochs = 5,\n",
    "        validation_data = test_iterator,\n",
    "        validation_steps = test_iterator.samples//32,\n",
    "        callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the directory to save the entire model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '.\\\\Saved_Model\\\\'\n",
    "    \n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    print(f'Path not present before. Created new: {path}')\n",
    "else:\n",
    "    print(f'Path present.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create unique timestamp:\n",
    "Prevents udesired overriting and finding the right model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t = time.localtime()\n",
    "timestamp = time.strftime('%d-%b-%Y_%H%M', t)\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model:\n",
    "The '.h5' extension indicates that the model should be saved to HDF5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = path+'CNN_Model_'+timestamp+'.h5'\n",
    "cnn.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the history:\n",
    "Progress per each epoch in  separate CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history_path = path+'CNN_Model_History_'+timestamp+'.csv'\n",
    "pd.DataFrame.from_dict(cnn.history.history).to_csv(model_history_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the just-saved model:\n",
    "Note: now the loaded model will not have the attribute 'history'. The history is saved in the 'CNN_Model_History_ ...' csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "cnn = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics history per batch:\n",
    "DataFrame containing: Accuracy, Validation Accuracy, Loss, Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_history = pd.DataFrame(cnn.history.history) #number of rows = number of epochs\n",
    "model_history = pd.read_csv(model_history_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load specific model with its history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = 'full path'\n",
    "# model_history_path = 'full path'\n",
    "\n",
    "# cnn = load_model(model_path)\n",
    "# model_history = pd.read_csv(model_history_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(model_history['accuracy'], label='Training');\n",
    "plt.plot(model_history['val_accuracy'], label='Validation');\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Model Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(model_history['loss'], label='Training');\n",
    "plt.plot(model_history['val_loss'], label='Validation');\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Model Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn.predict(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rounding predictions between 0 and 1 to integers and counting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_series = pd.Series(np.round(predictions.flatten(),0))\n",
    "predictions_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_iterator.classes, predictions_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6,5))\n",
    "sns.heatmap(confusion_matrix(test_iterator.classes, predictions_series), \n",
    "            cmap='viridis',\n",
    "            annot=True, fmt=\"d\", annot_kws={'size':18},\n",
    "            xticklabels = ['Pred. Covid-19', 'Pred. Normal'],\n",
    "            yticklabels = ['Act. Covid-19', 'Act. Normal']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_iterator.classes, predictions_series, target_names=['Covid-19', 'Normal']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
